{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages and dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import sys, warnings, os\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.core.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting columns and rows to display all the results\n",
    "pd.set_option(\"display.max_columns\", None, \"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>\n",
       "                        <style> div.text_cell_render{font-family: 'Montserrat';}\n",
       "                                .container { width:95% !important;}\n",
       "                        </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_notebook_config(width=True):\n",
    "    \"\"\"\n",
    "    Loads all neccesary configuration for the notebook's style:\n",
    "     - plots styling.\n",
    "     - pandas table sizes and limiting amount of float decimals.\n",
    "     - adjust the notebook cells width\n",
    "    \"\"\"\n",
    "    pd.options.display.max_columns = 0\n",
    "    pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    if width:\n",
    "        display(HTML(\"\"\"<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>\n",
    "                        <style> div.text_cell_render{font-family: 'Montserrat';}\n",
    "                                .container { width:95% !important;}\n",
    "                        </style>\"\"\"))\n",
    "load_notebook_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore warnings when validating scores\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Winner</th>\n",
       "      <th>title_bout</th>\n",
       "      <th>lose_streak_dif</th>\n",
       "      <th>win_streak_dif</th>\n",
       "      <th>longest_win_streak_dif</th>\n",
       "      <th>win_dif</th>\n",
       "      <th>loss_dif</th>\n",
       "      <th>total_round_dif</th>\n",
       "      <th>total_title_bout_dif</th>\n",
       "      <th>ko_dif</th>\n",
       "      <th>sub_dif</th>\n",
       "      <th>height_dif</th>\n",
       "      <th>reach_dif</th>\n",
       "      <th>age_dif</th>\n",
       "      <th>sig_str_dif</th>\n",
       "      <th>avg_sub_att_dif</th>\n",
       "      <th>avg_td_dif</th>\n",
       "      <th>draw_diff</th>\n",
       "      <th>avg_sig_str_pct_diff</th>\n",
       "      <th>avg_TD_pct_diff</th>\n",
       "      <th>win_by_Decision_Majority_diff</th>\n",
       "      <th>win_by_Decision_Split_diff</th>\n",
       "      <th>win_by_Decision_Unanimous_diff</th>\n",
       "      <th>win_by_TKO_Doctor_Stoppage_diff</th>\n",
       "      <th>odds_diff</th>\n",
       "      <th>ev_diff</th>\n",
       "      <th>kd_bout_diff</th>\n",
       "      <th>sig_str_landed_bout_diff</th>\n",
       "      <th>sig_str_attempted_bout_diff</th>\n",
       "      <th>sig_str_pct_bout_diff</th>\n",
       "      <th>tot_str_landed_bout_diff</th>\n",
       "      <th>tot_str_attempted_bout_diff</th>\n",
       "      <th>td_landed_bout_diff</th>\n",
       "      <th>td_attempted_bout_diff</th>\n",
       "      <th>td_pct_bout_diff</th>\n",
       "      <th>sub_attempts_bout_diff</th>\n",
       "      <th>pass_bout_diff</th>\n",
       "      <th>rev_bout_diff</th>\n",
       "      <th>Stance_diff</th>\n",
       "      <th>better_rank_enc</th>\n",
       "      <th>level_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-7</td>\n",
       "      <td>-27</td>\n",
       "      <td>-13</td>\n",
       "      <td>-57</td>\n",
       "      <td>-1</td>\n",
       "      <td>-17</td>\n",
       "      <td>-8</td>\n",
       "      <td>7.6200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-8</td>\n",
       "      <td>1.0500</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-332</td>\n",
       "      <td>-95.0549</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.7000</td>\n",
       "      <td>-5.0800</td>\n",
       "      <td>11</td>\n",
       "      <td>-3.1800</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>1.2100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-21</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4.2000</td>\n",
       "      <td>-1.1000</td>\n",
       "      <td>-1.0800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>-5.0800</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1.0900</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.6200</td>\n",
       "      <td>-7.6200</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.8200</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>2.8600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>130.5556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Winner  title_bout  lose_streak_dif  ...  rev_bout_diff  Stance_diff  better_rank_enc  level_0\n",
       "0      0       0           0                0  ...         0.0000            0               -1        0\n",
       "1      1       1           0                0  ...         0.0000            2               -1        1\n",
       "2      2       1           0               -1  ...         0.0000           -1               -1        2\n",
       "3      3       0           0                0  ...         0.0000           -1               -1        3\n",
       "4      4       0           0               -1  ...         0.0000            1                0        4\n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "df = pd.read_csv(\"../Resources/data_preprocessed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index is only needed for SQL join so we must drop it here so it doesnt effect outcomes\n",
    "index = ['index', 'level_0']\n",
    "df.drop(index, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish X variables and y target\n",
    "y = df.Winner\n",
    "X = df.drop(['Winner'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model w the training data\n",
    "rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>310</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>105</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          310          148\n",
       "Actual 1          105          579"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>310</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>105</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          310          148\n",
       "Actual 1          105          579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7784588441330998\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71       458\n",
      "           1       0.80      0.85      0.82       684\n",
      "\n",
      "    accuracy                           0.78      1142\n",
      "   macro avg       0.77      0.76      0.77      1142\n",
      "weighted avg       0.78      0.78      0.78      1142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00276661, 0.01342351, 0.01540536, 0.01933018, 0.02084814,\n",
       "       0.0229023 , 0.03097715, 0.01001945, 0.01686059, 0.01555615,\n",
       "       0.02620706, 0.03053441, 0.03312924, 0.03981271, 0.03136694,\n",
       "       0.03869132, 0.00244197, 0.02433504, 0.        , 0.00280308,\n",
       "       0.01154955, 0.01713814, 0.00313078, 0.06649627, 0.07322299,\n",
       "       0.02589769, 0.09371279, 0.03185838, 0.04309731, 0.05467295,\n",
       "       0.04129331, 0.02245628, 0.01210351, 0.02278072, 0.02191735,\n",
       "       0.03792105, 0.00351165, 0.01442107, 0.00540704])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate feature importance in the Random Forest model.\n",
    "importances = rf_model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.09371278924756822, 'sig_str_landed_bout_diff'),\n",
       " (0.07322299039122629, 'ev_diff'),\n",
       " (0.06649627355115442, 'odds_diff'),\n",
       " (0.05467294529755924, 'tot_str_landed_bout_diff'),\n",
       " (0.04309730671872242, 'sig_str_pct_bout_diff'),\n",
       " (0.041293308302487015, 'tot_str_attempted_bout_diff'),\n",
       " (0.03981271071059609, 'sig_str_dif'),\n",
       " (0.038691324197812044, 'avg_td_dif'),\n",
       " (0.03792105149725804, 'pass_bout_diff'),\n",
       " (0.03312924027637572, 'age_dif'),\n",
       " (0.0318583831513803, 'sig_str_attempted_bout_diff'),\n",
       " (0.031366939727302395, 'avg_sub_att_dif'),\n",
       " (0.030977152153706743, 'total_round_dif'),\n",
       " (0.03053441075092353, 'reach_dif'),\n",
       " (0.026207058330942615, 'height_dif'),\n",
       " (0.025897685861511234, 'kd_bout_diff'),\n",
       " (0.024335036416857133, 'avg_sig_str_pct_diff'),\n",
       " (0.02290230179793294, 'loss_dif'),\n",
       " (0.022780723959308514, 'td_pct_bout_diff'),\n",
       " (0.02245627665762514, 'td_landed_bout_diff'),\n",
       " (0.021917345103222123, 'sub_attempts_bout_diff'),\n",
       " (0.020848136817350923, 'win_dif'),\n",
       " (0.019330181830940606, 'longest_win_streak_dif'),\n",
       " (0.017138135156105915, 'win_by_Decision_Unanimous_diff'),\n",
       " (0.016860588676356744, 'ko_dif'),\n",
       " (0.015556149540612775, 'sub_dif'),\n",
       " (0.015405355453385393, 'win_streak_dif'),\n",
       " (0.014421074078504377, 'Stance_diff'),\n",
       " (0.013423505705208245, 'lose_streak_dif'),\n",
       " (0.01210350529804968, 'td_attempted_bout_diff'),\n",
       " (0.0115495521520556, 'win_by_Decision_Split_diff'),\n",
       " (0.010019448579594636, 'total_title_bout_dif'),\n",
       " (0.0054070386721871465, 'better_rank_enc'),\n",
       " (0.0035116495422187755, 'rev_bout_diff'),\n",
       " (0.003130775171274207, 'win_by_TKO_Doctor_Stoppage_diff'),\n",
       " (0.002803076296398146, 'win_by_Decision_Majority_diff'),\n",
       " (0.0027666052721854735, 'title_bout'),\n",
       " (0.0024419676560992133, 'draw_diff'),\n",
       " (0.0, 'avg_TD_pct_diff')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "107/107 [==============================] - 1s 1ms/step - loss: 0.6136 - accuracy: 0.6524\n",
      "Epoch 2/25\n",
      "107/107 [==============================] - 0s 931us/step - loss: 0.4674 - accuracy: 0.7746\n",
      "Epoch 3/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7697\n",
      "Epoch 4/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7748\n",
      "Epoch 5/25\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7806\n",
      "Epoch 6/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.7946\n",
      "Epoch 7/25\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7960\n",
      "Epoch 8/25\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7958\n",
      "Epoch 9/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.7934\n",
      "Epoch 10/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.7934\n",
      "Epoch 11/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8090\n",
      "Epoch 12/25\n",
      "107/107 [==============================] - 0s 988us/step - loss: 0.4076 - accuracy: 0.7994\n",
      "Epoch 13/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4005 - accuracy: 0.8025\n",
      "Epoch 14/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8133\n",
      "Epoch 15/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8097\n",
      "Epoch 16/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8162\n",
      "Epoch 17/25\n",
      "107/107 [==============================] - 0s 913us/step - loss: 0.3956 - accuracy: 0.8096\n",
      "Epoch 18/25\n",
      "107/107 [==============================] - 0s 950us/step - loss: 0.3820 - accuracy: 0.8264\n",
      "Epoch 19/25\n",
      "107/107 [==============================] - 0s 931us/step - loss: 0.3758 - accuracy: 0.8164\n",
      "Epoch 20/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8150\n",
      "Epoch 21/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8208\n",
      "Epoch 22/25\n",
      "107/107 [==============================] - 0s 903us/step - loss: 0.3695 - accuracy: 0.8376\n",
      "Epoch 23/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8398\n",
      "Epoch 24/25\n",
      "107/107 [==============================] - 0s 903us/step - loss: 0.3765 - accuracy: 0.8204\n",
      "Epoch 25/25\n",
      "107/107 [==============================] - 0s 922us/step - loss: 0.3793 - accuracy: 0.8279\n",
      "36/36 - 0s - loss: 0.4197 - accuracy: 0.7951\n",
      "Loss: 0.4197227954864502, Accuracy: 0.7950963377952576\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  25\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=25)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
